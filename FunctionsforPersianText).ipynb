{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1a818bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from hazm import stopwords_list, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da521c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df[\"NAME\"].str.isdigit()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4085999e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_terminal_names_starting_with_english_words(dataframe, column_name):\n",
    "    english_word_pattern = r'^[A-Za-z]+'\n",
    "\n",
    "    mask = dataframe[column_name].str.contains(english_word_pattern, case=False, regex=True)\n",
    "\n",
    "    dataframe = dataframe[~mask]\n",
    "\n",
    "    return dataframe\n",
    "filtered_df = drop_terminal_names_starting_with_english_words(df, 'NAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01965bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_persian_numbers(terminal_name):\n",
    "    persian_numbers = {'۰': '', '۱': '', '۲': '', '۳': '', '۴': '', '۵': '', '۶': '', '۷': '', '۸': '', '۹': ''}\n",
    "    pattern = re.compile('|'.join(persian_numbers.keys()))\n",
    "    result = pattern.sub(lambda x: persian_numbers[x.group()], terminal_name)\n",
    "    return result\n",
    "filtered_df['NAME'] = filtered_df['NAME'].apply(remove_persian_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac16799b",
   "metadata": {},
   "outputs": [],
   "source": [
    "persian_stopwords = stopwords_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e3a941",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_terminal_names = []\n",
    "for terminal_name in filtered_df['NAME']:\n",
    "    tokens = word_tokenize(terminal_name)\n",
    "    \n",
    "    filtered_tokens = [word for word in tokens if word not in persian_stopwords]\n",
    "    \n",
    "    processed_terminal_name = ' '.join(filtered_tokens)\n",
    "    \n",
    "    processed_terminal_names.append(processed_terminal_name)\n",
    "filtered_df['processed_name'] =processed_terminal_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f43ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_persian_numbers_from_column(df, column_name):\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise TypeError(\"Input must be a pandas DataFrame\")\n",
    "\n",
    "    if column_name not in df.columns:\n",
    "        raise ValueError(f\"Column '{column_name}' not found in the DataFrame\")\n",
    "\n",
    "    persian_number_pattern = '[۰-۹]'\n",
    "\n",
    "    df[column_name] = df[column_name].apply(lambda text: re.sub(persian_number_pattern, '', str(text)))\n",
    "\n",
    "    return df\n",
    "filtered_df = remove_persian_numbers_from_column(filtered_df, 'TERMINAL_NAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8cfc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_emojis_and_symbols(text):\n",
    "    emoji_symbol_pattern = re.compile(\"[\"\n",
    "                                      u\"\\U0001F600-\\U0001F64F\"  # Emoticons\n",
    "                                      u\"\\U0001F300-\\U0001F5FF\"  # Symbols & pictographs\n",
    "                                      u\"\\U0001F680-\\U0001F6FF\"  # Transport & map symbols\n",
    "                                      u\"\\U0001F700-\\U0001F77F\"  # Alphanumeric & geometric shapes\n",
    "                                      u\"\\U0001F780-\\U0001F7FF\"  # Geometric shapes extended\n",
    "                                      u\"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
    "                                      u\"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "                                      u\"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n",
    "                                      u\"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
    "                                      u\"\\U00002702-\\U000027B0\"  # Dingbats\n",
    "                                      u\"\\U000024C2-\\U0001F251\" \n",
    "                                      r\"\\W\"  # Non-word characters (symbols)\n",
    "                                      \"]+\", flags=re.UNICODE)\n",
    "\n",
    "    # Remove emojis and symbols from the text\n",
    "    clean_text = re.sub(emoji_symbol_pattern, ' ', text)\n",
    "\n",
    "    return clean_text\n",
    "filtered_df['cleaned_name'] = filtered_df['processed_name'].apply(remove_emojis_and_symbols)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
